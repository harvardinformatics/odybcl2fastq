'''
snakemake workflow for 10x single cell

Created on  2019-03-25

@author: Meghan Correa <mportermahoney@g.harvard.edu>
@copyright: 2019 The Presidents and Fellows of Harvard College. All rights reserved.
@license: GPL v2.0
'''

configfile: "snakemake_config.json"
localrules: all, update_lims_db, cp_source_to_output, checksum, publish, demultiplex_10x_cmd, count_10x_cmd, fastqc_cmd, fastq_email
from odybcl2fastq.run import update_lims_db, setup_run_logger
from odybcl2fastq.parsers.samplesheet import SampleSheet
from odybcl2fastq.emailbuilder.emailbuilder import buildmessage
from odybcl2fastq import config as ody_config
import odybcl2fastq.util as util
import pandas as pd
import os

# parse sample sheet for sample names
sample_sheet_path = "%s%s/SampleSheet.csv" % (config['source'], config['run'])
with open(sample_sheet_path, 'r') as ln:
    idx = next(i for i, j in enumerate(ln) if j.startswith('[Data]'))
data = pd.read_csv(sample_sheet_path, skiprows=idx+1)

samples = list(data['Sample_ID'])
projects = list(data['Sample_Project'])
STATUS_DIR = 'status_test'

onstart:
    """
    touch processed file to prevent reprocessing
    prepare log, script and status dirs
    """
    shell("mkdir -p {source}{run}/{status}", source={config['source']}, run=config['run'], status=STATUS_DIR)
    shell("touch {source}{run}/{status}/ody.processed", source=config['source'], run=config['run'], status=STATUS_DIR)
    shell("mkdir -p {output}{run}", output={config['output']}, run=config['run'])
    shell("mkdir -p {output}{run}/log", output={config['output']}, run=config['run'])
    shell("mkdir -p {output}{run}/script", output={config['output']}, run=config['run'])

rule all:
    """
    final output of workflow
    """
    input:
        #expand("{source}{run}/{status}/ody.complete", source=config['source'], run=config['run'], status=STATUS_DIR)
        expand("{source}{run}/{status}/demultiplex.processed", source=config['source'], run=config['run'], status=STATUS_DIR)

rule demultiplex_10x_cmd:
    """
    build a bash file with the demux cmd
    """
    input:
        run_dir=expand("{source}{{run}}/SampleSheet.csv", source=config['source'])
    output:
        expand("{output}{{run}}/script/demultiplex_10x.sh", output=config['output'])
    shell:
        """
        cmd="#!/bin/bash\n"
        cmd+="module purge\n"
        cmd+="module load cellranger/3.0.1-fasrc01\n\n"
        cmd+="mkdir -p {config[output_slurm]}{wildcards.run}/fastq\n"
        cmd+="cd {config[output_slurm]}{wildcards.run}/fastq\n"
        cmd+="cellranger mkfastq --ignore-dual-index --run={config[source_slurm]}{wildcards.run} --samplesheet={config[source_slurm]}{wildcards.run}/SampleSheet.csv --output-dir={config[output_slurm]}{wildcards.run}/fastq"
        echo "$cmd" >> {output}
        chmod 777 {output}
        """

rule demultiplex_10x:
    """
    run bash file for demux
    the slurm_submit.py script will add slurm params to the top of this file
    """
    input:
        expand("{output}{{run}}/script/demultiplex_10x.sh", output=config['output'])
    output:
        touch(expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR))
    shell:
        """
        {input}
        """

rule count_10x_cmd:
    """
    build a bash file with the demux cmd
    """
    input:
        expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR),
        expand("{source}{{run}}/{status}/fastq_email.processed", source=config['source'], status=STATUS_DIR)
    output:
        expand("{output}{{run}}/script/{{project}}.{{sample}}_count.sh", output=config['output'])
    shell:
        """
        fastq_path="{config[output_slurm]}{wildcards.run}/fastq/{wildcards.project}/{wildcards.sample}"
        cmd="#!/bin/bash\n"
        cmd+="module purge\n"
        cmd+="module load cellranger/3.0.1-fasrc01\n\n"
        cmd+="mkdir -p {config[output_slurm]}{wildcards.run}/count\n"
        cmd+="cd {config[output_slurm]}{wildcards.run}/count\n"
        cmd+="cellranger count --id={wildcards.sample} --transcriptome={config[ref_slurm]} --sample={wildcards.sample} --fastqs=$fastq_path"
        echo "$cmd" >> {output}
        chmod 777 {output}
        """

rule count_10x:
    """
    run bash file for count
    the slurm_submit.py script will add slurm params to the top of this file
    """
    input:
        script=expand("{output}{{run}}/script/{{project}}.{{sample}}_count.sh", output=config['output'])
    output:
        touch(expand("{source}{{run}}/{status}/{{project}}.{{sample}}_count.processed", source=config['source'], status=STATUS_DIR))
    shell:
        """
        {input}
        """

rule update_lims_db:
    """
    connect the submission with the run in lims
    """
    input:
        expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR),
        sample_sheet=expand("{source}{{run}}/SampleSheet.csv", source=config['source'])
    output:
        touch(expand("{source}{{run}}/{status}/update_lims_db.processed", source=config['source'], status=STATUS_DIR))
    run:
        setup_run_logger(wildcards.run, False)
        sample_sheet = SampleSheet(input.sample_sheet[0])
        instrument = sample_sheet.get_instrument()
        run_folder = config['source'] + wildcards.run
        update_lims_db(run_folder, sample_sheet.sections, instrument)

rule fastqc_cmd:
    """
    build a bash file with the fastqc cmd
    """
    input:
        ancient(expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR))
    output:
        expand("{output}{{run}}/script/fastqc.sh", output=config['output'])
    shell:
        """
        cmd="#!/bin/bash\n"
        cmd+="module purge\n"
        cmd+="module load fastqc/0.11.5-fasrc01\n\n"
        cmd+="mkdir -p {config[output_slurm]}{wildcards.run}/QC\n"
        cmd+="fastqc -o {config[output_slurm]}{wildcards.run}/QC --threads 1 -b $(find {config[output_slurm]}{wildcards.run}/fastq/ -name *.fastq.gz -not -name Undetermined* -print0 | xargs -0)"
        echo "$cmd" >> {output}
        chmod 777 {output}
        """

rule fastqc:
    """
    run bash file for fastqc
    the slurm_submit.py script will add slurm params to the top of this file
    """
    input:
        expand("{output}{{run}}/script/fastqc.sh", output=config['output'])
    output:
        touch(expand("{source}{{run}}/{status}/fastqc.processed", source=config['source'], status=STATUS_DIR))
    shell:
        """
        {input}
        """

rule cp_source_to_output:
    """
    copy a few files from source to output dir
    """
    input:
        expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR)
    params:
        sample_sheet="SampleSheet.csv",
        run_info="RunInfo.xml",
        interop="InterOp",
        nextseq_run_params="RunParameters.xml",
        hiseq_run_params="runParameters.xml"
    output:
        sample_sheet=expand("{output}{{run}}/SampleSheet.csv", output=config['output']),
        run_info=expand("{output}{{run}}/RunInfo.xml", output=config['output']),
        interop=directory(expand("{output}{{run}}/InterOp", output=config['output']))
    shell:
        """
        cp {config[source]}{wildcards.run}/{params.sample_sheet} {output.sample_sheet}
        cp {config[source]}{wildcards.run}/{params.run_info} {output.run_info}
        rsync -rt {config[source]}{wildcards.run}/{params.interop}/ {output.interop}/
        # copy these if they exist
        cp {config[source]}{wildcards.run}/{params.nextseq_run_params} {config[output]}{wildcards.run}/{params.nextseq_run_params} 2>/dev/null || :
        cp {config[source]}{wildcards.run}/{params.hiseq_run_params} {config[output]}{wildcards.run}/{params.hiseq_run_params} 2>/dev/null || :

        """

rule checksum:
    """
    calculate checksum for all the fastq files
    """
    input:
        expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR)
    output:
        checksum=expand("{output}{{run}}/md5sum.txt", output=config['output']),
    shell:
        """
        files=$(find {config[output]}{wildcards.run}/ -name *.fastq.gz -print0 | xargs -0)
        md5sum $files > {output.checksum}
        """

rule fastq_email:
    """
    copy fastq files to final and send an email that fastq files are ready, this step is run only for jobs
    running count
    """
    input:
        checksum=expand("{output}{{run}}/md5sum.txt", output=config['output']),
        fastqc=expand("{source}{{run}}/{status}/fastqc.processed", source=config['source'], status=STATUS_DIR),
        lims=expand("{source}{{run}}/{status}/update_lims_db.processed", source=config['source'], status=STATUS_DIR),
        demultiplex=expand("{source}{{run}}/{status}/demultiplex.processed", source=config['source'], status=STATUS_DIR)
    output:
        touch(expand("{source}{{run}}/{status}/fastq_email.processed", source=config['source'], status=STATUS_DIR))
    run:
        shell("cp -r {config[output]}{wildcards.run} {config[published]}")
        subject = 'Demultiplex Summary for: %s (count pending)' % config['run']
        send_success_email(subject)

def publish_input(wildcards):
    """
    determine which files need to be ready to publish the run
    count is not run if there is not reference genome
    """
    input = {
        'checksum': "%s%s/md5sum.txt" % (config['output'], wildcards.run),
        'fastqc': "%s%s/%s/fastqc.processed" % (config['source'], wildcards.run, STATUS_DIR),
        'lims': "%s%s/%s/update_lims_db.processed" % (config['source'], wildcards.run, STATUS_DIR)
    }
    # if reference is provided then run count
    if config['ref']:
        # copy fastq to final and send an email that count is pending
        input['email'] = "%s%s/%s/fastq_email.processed" % (config['source'], wildcards.run, STATUS_DIR)
        for i, sample in enumerate(samples):
            project = projects[i]
            key = 'count_%s.%s' % (project, sample)
            input[key] = "%s%s/%s/%s.%s_count.processed" % (config['source'], wildcards.run, STATUS_DIR, project, sample)
    return input


rule publish:
    """
    copy all output to a published location
    """
    input:
        unpack(publish_input)
    output:
        touch(expand("{source}{{run}}/{status}/ody.complete", source=config['source'], status=STATUS_DIR))
    shell:
        """
        rsync -rt --perms --chmod=Dug=rwx,Do=rx,Fug=rw,Fo=r {config[output]}{wildcards.run}/ {config[published]}{wildcards.run}/
        """

onsuccess:
    subject = 'Demultiplex Summary for: %s' % config['run']
    #send_success_email(subject)

onerror:
    message = 'run %s failed\n see logs here: %s%s.log\n' % (config['run'], config['log'], config['run'])
    subject = 'Run Failed: %s' % config['run']
    #sent = buildmessage(message, subject, {}, ody_config.EMAIL['from_email'], ody_config.EMAIL['admin_email'])

def get_summary_data(cmd, run, ss_file):
    sample_sheet = util.get_file_contents(ss_file)
    assumptions = [
        'chromium single-cell RNA-seq',
        'ignoring the second index on a dual-indexed flowcell'
    ]
    versions = [
        'cellranger 3.0.1',
        'fastqc 0.11.5'
    ]
    if config['ref']:
        assumptions.append('reference genome %s, see annotation under versions below' % os.path.basename(config['ref']))
        assumptions.append('samples are full cell, not nuclei')
        versions.append('annotation gtf: %s' % config['gtf'])
    summary_data = {
        'fastq_url': ody_config.FASTQ_URL,
        'fastq_dir': ody_config.MOUNT_DIR,
        'versions': versions,
        'run': run,
        'run_folder': run,
        'cmd': cmd,
        'sample_sheet_file': ss_file,
        'sample_sheet': sample_sheet,
        'assumptions': assumptions
    }
    return summary_data

def send_success_email(subject):
    message = 'run %s completed successfully\n see logs here: %s%s.log\n' % (config['run'], config['log'], config['run'])
    cmd_file = '%s%s/script/demultiplex_10x.sh' % (config['output'], config['run'])
    cmd = util.get_file_contents(cmd_file)
    ss_file = '%s%s/SampleSheet.csv' % (config['source'], config['run'])
    summary_data = get_summary_data(cmd, config['run'], ss_file)
    sent = buildmessage(message, subject, summary_data, ody_config.EMAIL['from_email'], ody_config.EMAIL['to_email'], '10x_summary.html')
